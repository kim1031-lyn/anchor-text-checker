import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
import mammoth 
import io
from streamlit_copy_button import copy_button # å¯¼å…¥å¤åˆ¶æŒ‰é’®åŠŸèƒ½

# --- é¡µé¢åŸºç¡€è®¾ç½® ---
st.set_page_config(page_title="CheckCheckCheck Pro", layout="wide")

# --- æ ·å¼å®šä¹‰ ---
st.markdown("""
<style>
    .stButton>button {
        width: 100%;
    }
    .stDataFrame {
        width: 100%;
    }
    /* å¤åˆ¶æŒ‰é’®çš„æ ·å¼å¯ä»¥å¾®è°ƒ */
    div[data-testid="stCopyButton"] button {
        width: auto;
        padding: 4px 10px;
    }
</style>
""", unsafe_allow_html=True)

# --- æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---

def get_domain_from_url(url):
    try:
        return urlparse(url).hostname.replace('www.', '')
    except:
        return ''

def extract_publish_date(soup):
    selectors = [
        'meta[property="article:published_time"]', 'meta[property="og:published_time"]',
        'meta[name="publication_date"]', 'meta[name="publishdate"]', 'meta[name="date"]',
    ]
    for selector in selectors:
        element = soup.select_one(selector)
        if element and element.get('content'):
            return element.get('content').split('T')[0]
    time_tag = soup.select_one('time[datetime]')
    if time_tag and time_tag.get('datetime'):
        return time_tag.get('datetime').split('T')[0]
    return "æœªæ‰¾åˆ°"

def fetch_and_parse_url(url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')
        publish_date = extract_publish_date(soup)
        anchors_data = []
        main_content = soup.select_one('main, article, .post-content, #content')
        container = main_content if main_content else soup.body
        for a in container.find_all('a', href=True):
            text = a.get_text(strip=True)
            href_raw = a.get('href')
            if not text or not href_raw: continue
            href = urljoin(url, href_raw)
            target_domain = get_domain_from_url(href)
            if not target_domain: continue
            rel = a.get('rel', [])
            follow_type = 'nofollow' if 'nofollow' in rel else 'dofollow'
            anchors_data.append({
                "æ¥æºé¡µé¢": url, "æ–‡ç« ä¸Šçº¿æ—¶é—´": publish_date, "é”šæ–‡æœ¬": text,
                "ç›®æ ‡é“¾æ¥": href, "ç›®æ ‡åŸŸå": target_domain, "é“¾æ¥ç±»å‹": follow_type,
            })
        return anchors_data
    except requests.RequestException as e:
        st.error(f"æŠ“å–å¤±è´¥: {url} (åŸå› : {e})")
        return []

def extract_links_from_docx(uploaded_file):
    try:
        result = mammoth.convert_to_html(uploaded_file)
        html_content = result.value
        soup = BeautifulSoup(html_content, 'html.parser')
        links = []
        for a in soup.find_all('a', href=True):
            text = a.get_text(strip=True)
            href = a.get('href')
            if text and href:
                links.append({"é”šæ–‡æœ¬": text, "é“¾æ¥åœ°å€": href})
        if not links:
            st.warning("åœ¨æ–‡æ¡£ä¸­æœªæ‰¾åˆ°ä»»ä½•é“¾æ¥ã€‚")
            return pd.DataFrame()
        return pd.DataFrame(links)
    except Exception as e:
        st.error(f"è§£æWordæ–‡æ¡£å¤±è´¥: {e}")
        return pd.DataFrame()

# --- ä¸»åº”ç”¨ç•Œé¢ä¸é€»è¾‘ ---

def main_app():
    st.title("ğŸš€ CheckCheckCheck Pro (æœ€ç»ˆç‰ˆ)")

    tab1, tab2 = st.tabs(["ğŸ”— ç½‘å€é”šæ–‡æœ¬æå–", "ğŸ“„ Wordæ–‡æ¡£é“¾æ¥æå–"])

    with tab1:
        st.header("ä»ç½‘é¡µURLæå–é“¾æ¥")
        url_input = st.text_area("è¾“å…¥ç½‘å€ (æ¯è¡Œä¸€ä¸ª)", height=150, placeholder="https://example.com/page1\nhttps://example.com/page2", key="url_input")
        if st.button("ğŸš€ å¼€å§‹æå– (åç«¯æ¨¡å¼)", type="primary"):
            urls = [u.strip() for u in url_input.split('\n') if u.strip()]
            if not urls:
                st.warning("è¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªæœ‰æ•ˆç½‘å€ã€‚")
            else:
                all_results = []
                progress_bar = st.progress(0, text="å‡†å¤‡å¼€å§‹æŠ“å–...")
                for i, url in enumerate(urls):
                    progress_bar.progress((i) / len(urls), text=f"æ­£åœ¨æŠ“å–: {url}")
                    results = fetch_and_parse_url(url)
                    if results: all_results.extend(results)
                progress_bar.progress(1.0, text="æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼")

                if not all_results:
                    st.warning("æœªèƒ½ä»ä»»ä½•ç½‘å€ä¸­æå–åˆ°æœ‰æ•ˆé“¾æ¥ã€‚")
                    if 'url_results_df' in st.session_state:
                        del st.session_state['url_results_df']
                else:
                    st.session_state.url_results_df = pd.DataFrame(all_results)
        
        df_to_show = pd.DataFrame() # ä¿è¯df_to_showä¸€å®šå­˜åœ¨
        if 'url_results_df' in st.session_state and not st.session_state.url_results_df.empty:
            st.success(f"æå–å®Œæˆï¼å…±æ‰¾åˆ° {len(st.session_state.url_results_df)} æ¡é”šæ–‡æœ¬é“¾æ¥ã€‚")
            df_to_show = st.session_state.url_results_df.copy()
            col1, col2 = st.columns(2)
            with col1:
                source_options = ["æ‰€æœ‰æ¥æº"] + list(df_to_show["æ¥æºé¡µé¢"].unique())
                selected_source = st.selectbox("ç­›é€‰æ¥æºé¡µé¢:", source_options)
                if selected_source != "æ‰€æœ‰æ¥æº": df_to_show = df_to_show[df_to_show["æ¥æºé¡µé¢"] == selected_source]
            with col2:
                domain_options = ["æ‰€æœ‰åŸŸå"] + list(df_to_show["ç›®æ ‡åŸŸå"].unique())
                selected_domain = st.selectbox("ç­›é€‰ç›®æ ‡åŸŸå:", domain_options)
                if selected_domain != "æ‰€æœ‰åŸŸå": df_to_show = df_to_show[df_to_show["ç›®æ ‡åŸŸå"] == selected_domain]
            st.dataframe(df_to_show, use_container_width=True)
            
            @st.cache_data
            def convert_df_to_csv(df): return df.to_csv(index=False).encode('utf-8-sig')
            csv = convert_df_to_csv(df_to_show)
            st.download_button(label="ğŸ“¥ ä¸‹è½½å½“å‰ç­›é€‰ç»“æœ (CSV)", data=csv, file_name="url_link_results.csv", mime="text/csv")
        
        # ========= æ–°å¢ï¼šå•è¡Œå†…å®¹å¤åˆ¶åŠŸèƒ½ =========
        st.markdown("---")
        st.subheader("ğŸ“‹ å•è¡Œå†…å®¹å¤åˆ¶")

        if not df_to_show.empty:
            # ä¸ºäº†åœ¨é€‰æ‹©æ¡†ä¸­æ˜¾ç¤ºæ¸…æ™°ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„æ˜¾ç¤ºåˆ—
            df_to_show['display_text'] = "é”šæ–‡æœ¬: " + df_to_show['é”šæ–‡æœ¬'].str.slice(0, 30) + "... | ç›®æ ‡: " + df_to_show['ç›®æ ‡é“¾æ¥'].str.slice(0, 40) + "..."
            
            # ä½¿ç”¨ç´¢å¼•ä½œä¸ºé€‰é¡¹ï¼Œè¿™æ ·æ›´ç¨³å®š
            selected_index = st.selectbox(
                "é€‰æ‹©è¦å¤åˆ¶çš„è¡Œ:",
                options=df_to_show.index,
                format_func=lambda x: df_to_show.loc[x, 'display_text']
            )

            if selected_index is not None:
                selected_row = df_to_show.loc[selected_index]
                anchor_text_to_copy = selected_row['é”šæ–‡æœ¬']
                link_to_copy = selected_row['ç›®æ ‡é“¾æ¥']

                col_copy_1, col_copy_2 = st.columns(2)
                with col_copy_1:
                    st.text_area("è¦å¤åˆ¶çš„é”šæ–‡æœ¬", anchor_text_to_copy, height=100, key="copy_anchor")
                    copy_button(anchor_text_to_copy, "å¤åˆ¶é”šæ–‡æœ¬")
                
                with col_copy_2:
                    st.text_area("è¦å¤åˆ¶çš„ç›®æ ‡é“¾æ¥", link_to_copy, height=100, key="copy_link")
                    copy_button(link_to_copy, "å¤åˆ¶ç›®æ ‡é“¾æ¥")
        else:
            st.info("å½“å‰æ²¡æœ‰å¯å¤åˆ¶çš„æ•°æ®ã€‚")


    with tab2:
        st.header("ä»Wordæ–‡æ¡£ (.docx) æå–é“¾æ¥")
        uploaded_file = st.file_uploader("ä¸Šä¼ ä¸€ä¸ª.docxæ–‡ä»¶", type=["docx"], key="docx_uploader")
        
        if uploaded_file is not None:
            with st.spinner("æ­£åœ¨è§£ææ–‡æ¡£..."):
                st.session_state.docx_df = extract_links_from_docx(uploaded_file)
        
        if 'docx_df' in st.session_state and not st.session_state.docx_df.empty:
            df_docx_to_show = st.session_state.docx_df
            st.success(f"è§£æå®Œæˆï¼å…±æ‰¾åˆ° {len(df_docx_to_show)} æ¡é“¾æ¥ã€‚")
            st.dataframe(df_docx_to_show, use_container_width=True)
            
            @st.cache_data
            def convert_df_to_csv_docx(df): return df.to_csv(index=False).encode('utf-8-sig')

            csv_docx = convert_df_to_csv_docx(df_docx_to_show)
            st.download_button(label="ğŸ“¥ ä¸‹è½½ç»“æœ (CSV)", data=csv_docx, file_name="docx_link_results.csv", mime="text/csv", key="docx_downloader")


# --- ç™»å½•ä¸è·¯ç”±é€»è¾‘ (ä¿æŒä¸å˜) ---
if 'users' not in st.session_state: st.session_state['users'] = {"admin": "1008611"}
if 'logged_in' not in st.session_state: st.session_state['logged_in'] = False

def login():
    st.title("ç™»å½•")
    username = st.text_input("ç”¨æˆ·å")
    password = st.text_input("å¯†ç ", type="password")
    if st.button("ç™»å½•"):
        if username in st.session_state['users'] and st.session_state['users'][username] == password:
            st.session_state['logged_in'] = True
            st.success(f"æ¬¢è¿ {username}ï¼")
            st.rerun()
        else:
            st.error("ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")

def add_user():
    st.title("æ·»åŠ æ–°ç”¨æˆ·")
    new_user = st.text_input("æ–°ç”¨æˆ·å")
    new_pass = st.text_input("æ–°å¯†ç ", type="password")
    if st.button("æ·»åŠ ç”¨æˆ·"):
        if new_user in st.session_state['users']: st.warning("ç”¨æˆ·å·²å­˜åœ¨ï¼")
        elif not new_user or not new_pass: st.warning("ç”¨æˆ·åå’Œå¯†ç ä¸èƒ½ä¸ºç©ºï¼")
        else:
            st.session_state['users'][new_user] = new_pass
            st.success(f"æ·»åŠ ç”¨æˆ· {new_user} æˆåŠŸï¼")

if not st.session_state['logged_in']:
    login()
else:
    st.sidebar.title("ç®¡ç†èœå•")
    option = st.sidebar.selectbox("é€‰æ‹©æ“ä½œ", ["ä¸»é¡µ", "æ·»åŠ ç”¨æˆ·", "é€€å‡ºç™»å½•"])
    if option == "ä¸»é¡µ": main_app()
    elif option == "æ·»åŠ ç”¨æˆ·": add_user()
    elif option == "é€€å‡ºç™»å½•":
        st.session_state['logged_in'] = False
        st.rerun()